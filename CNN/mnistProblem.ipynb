{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import cuda\n",
    "\n",
    "#SciKit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#matplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading [Mnist](https://keras.io/api/datasets/mnist/) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(123)\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train/255\n",
    "x_test =x_test/255\n",
    "\n",
    "y_train_onehot = keras.utils.to_categorical(y_train, 10)\n",
    "y_test_onehot = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_train[0]\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = keras.metrics.Precision()\n",
    "recall = keras.metrics.Recall()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy', precision, recall])\n",
    "\n",
    "history = model.fit(x_train, y_train_onehot,\n",
    "          batch_size=128, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating metrics between testing and training phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test_onehot, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in ['accuracy', 'precision_2', 'recall_2']:\n",
    "    plt.plot(history.epoch, history.history[metric], label=metric+'_train')\n",
    "\n",
    "\n",
    "plt.plot(history.epoch, np.full(5, score[1]), label='accuracy_test')\n",
    "plt.plot(history.epoch, np.full(5, score[2]), label='precision_test')\n",
    "plt.plot(history.epoch, np.full(5, score[3]), label='recall_test')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('train epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷ = model.predict(x_test)\n",
    "y_pred = [np.argmax(yi) for yi in ŷ]\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeFeatureMap(img, model, nth_layer):\n",
    "    # visualize the feature map off input<img> at model<model> on convolution layer<nth_layer>\n",
    "\n",
    "    # Create a model that will return these outputs, given the model input\n",
    "    feature_map_model = Model(inputs=model.inputs, outputs=model.layers[nth_layer].output)\n",
    "\n",
    "    # Use the model to predict the features\n",
    "    feature_maps = feature_map_model.predict(\n",
    "        img.reshape(1, img.shape[0], img.shape[1], img.shape[2] if len(img.shape)==3 else 1), verbose = 0)\n",
    "\n",
    "\n",
    "    numOfFeatureMaps = model.layers[nth_layer].output.shape[3]\n",
    "    gridAxisDim = np.int16(np.ceil(np.sqrt(numOfFeatureMaps)))\n",
    "    for i in range(numOfFeatureMaps):\n",
    "        plt.subplot(gridAxisDim, gridAxisDim, i+1)\n",
    "        plt.imshow(feature_maps[0, :, :, i], cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeFeatureMap(img, model, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    num = i\n",
    "    filter = y_test == num\n",
    "\n",
    "    x_test_num = x_test[filter]\n",
    "    y_test_num = y_test[filter]\n",
    "\n",
    "    visualizeFeatureMap(x_test_num[0], model, 0)\n",
    "    visualizeFeatureMap(x_test_num[0], model, 2)\n",
    "    print('----------------------------------------------------------')\n",
    "    visualizeFeatureMap(x_test_num[1], model, 0)\n",
    "    visualizeFeatureMap(x_test_num[1], model, 2)\n",
    "    print('----------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CNN LeNet aproach for MNIST classification problem proved to be better than MLP because the number of parameters.\n",
    "\n",
    "LeNet has 44.426 parameters and my MLP approach has 1.024.080.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
